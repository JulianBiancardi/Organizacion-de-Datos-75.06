{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81734d0-a484-4c21-8640-6d12e556325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import auxiliar as aux \n",
    "from preprocessing import apply_ODE, init_dataset, discretize_columns, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fa3f1-0054-4e60-b520-07a6740aa961",
   "metadata": {},
   "source": [
    "# **Ensamble Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0d00b-e0ff-40f2-bfc3-967d207febb3",
   "metadata": {},
   "source": [
    "Vamos a realizar un ensamble con los siguientes modelos: \n",
    "\n",
    "    - GuassianNB: para las columnas numéricas\n",
    "    - CategoricalNB: para las columnas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25975bda-1e0b-4189-b161-4c898d4b2c7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Obtenemos el dataset con el cual entrenaremos nuestro modelo. Para este modelo se opto unicamente tratar los missings como categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdb1329-822f-4751-b3b4-7a3ef2ea7353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,y = aux.get_train_set()\n",
    "X = init_dataset(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5afeb-68e1-4859-8a05-89dc288d653f",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67194f6-c80c-4c74-adc6-7ffbbfd9ab64",
   "metadata": {},
   "source": [
    "Para aplicar este tipo de modelo debemos quedarnos solo con las columnas continuas. En este caso no nos hace falta aplicar OHE, puesto que todas las columnas que nos quedan son numéricas. Tampoco nos sirve los preprocesamientos de reduccion por frecuencia o discretizacion, puesto que esto eliminaria o generaria nuevas columnas categoricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb58c161-f0e1-494b-a777-91e93a80b814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anios_estudiados</th>\n",
       "      <th>edad</th>\n",
       "      <th>ganancia_perdida_declarada_bolsa_argentina</th>\n",
       "      <th>horas_trabajo_registradas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>2174</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anios_estudiados  edad  ganancia_perdida_declarada_bolsa_argentina  \\\n",
       "0                17    39                                        2174   \n",
       "1                17    50                                           0   \n",
       "2                13    38                                           0   \n",
       "3                11    53                                           0   \n",
       "4                17    28                                           0   \n",
       "\n",
       "   horas_trabajo_registradas  \n",
       "0                         40  \n",
       "1                         13  \n",
       "2                         40  \n",
       "3                         40  \n",
       "4                         40  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_continuos = X.select_dtypes(include=['int64','int32'])\n",
    "X_continuos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac68efa-cc98-4019-ae98-f11afdfe8d19",
   "metadata": {},
   "source": [
    "Ahora realizamos un escalado a nuestras columnas continuas. El rango de escalado es entre (0,1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d3eb99-106d-4d9d-9e36-2013e038e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84210526, 0.30136986, 0.06257486, 0.39795918],\n",
       "       [0.84210526, 0.45205479, 0.04174213, 0.12244898],\n",
       "       [0.63157895, 0.28767123, 0.04174213, 0.39795918],\n",
       "       ...,\n",
       "       [0.63157895, 0.56164384, 0.04174213, 0.39795918],\n",
       "       [0.63157895, 0.06849315, 0.04174213, 0.19387755],\n",
       "       [0.63157895, 0.47945205, 0.18571223, 0.39795918]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gauss = scale(X_continuos)\n",
    "X_gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99d0b7-929e-4c1d-b33e-fe1b577e2d2d",
   "metadata": {},
   "source": [
    "Partimos nuestro set en *train* y *validation*, dejaremos un 20% de los datos para validación de nuestro entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee326d6-7030-415b-9464-1503df53ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_gauss, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f34563-d345-4cd9-bf6a-b1c22c5803e3",
   "metadata": {},
   "source": [
    "Buscamos los mejores hiperparámetros para el modelo gaussiano con GridSearchCV. La métrica que se utiliza para comparar los modelos obtenidos en cada iteracion es *roc_auc_score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7984df6e-e27b-4aba-bd74-b674a65ba2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor score ROC-AUC en Entrenamiento: 0.836209464438614\n",
      "Mejores Parametros {'var_smoothing': 9.9e-07}\n",
      "\n",
      "Mejor score ROC-AUC en Validación: 0.8343866072718269\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'var_smoothing': np.arange(0, 1e-6, 1e-8)\n",
    "}\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    clf, parameters, scoring='roc_auc',n_jobs=-1, cv=5, return_train_score=True\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejor score ROC-AUC en Entrenamiento: {gscv.best_score_}\")\n",
    "print(f\"Mejores Parametros {gscv.best_params_}\")\n",
    "\n",
    "print(f\"\\nMejor score ROC-AUC en Validación: {gscv.score(X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1375ddb-2227-43c4-9d0d-5c83550bcd0c",
   "metadata": {},
   "source": [
    "Armamos el modelo de GaussianNB con los hiperparametros calculados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62a6b9b-f071-4b3d-87b3-a260338fe1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=9.9e-07)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gaussianNB = gscv.best_estimator_\n",
    "model_gaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab621590-01c4-4530-9e80-9d2383dd4d78",
   "metadata": {},
   "source": [
    "Predecimos con el validation set. A diferencia de todos los otros modelos, aqui predecimos la probabilidades de pertenecer a dicha cateogria lo cual nos servira mas adelante cuando querramos realizar el ensamble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce6fb7a-92de-462b-b456-ee3a25d56f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB_predict = model_gaussianNB.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be8aa13-e2c5-44ae-b25c-12096e3f388e",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abf989-5494-4279-a8ca-0e00c1f3c1e8",
   "metadata": {},
   "source": [
    "Para aplicar este tipo de modelo debemos quedarnos solo con columnas categóricas para luego aplicar Ordinal Encoder (ODE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7a0d20-9509-47a3-bef7-bcc22a118a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrio</th>\n",
       "      <th>categoria_de_trabajo</th>\n",
       "      <th>estado_marital</th>\n",
       "      <th>genero</th>\n",
       "      <th>religion</th>\n",
       "      <th>rol_familiar_registrado</th>\n",
       "      <th>trabajo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>palermo</td>\n",
       "      <td>empleado_provincial</td>\n",
       "      <td>sin_matrimonio</td>\n",
       "      <td>hombre</td>\n",
       "      <td>cristianismo</td>\n",
       "      <td>sin_familia</td>\n",
       "      <td>entretenimiento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>palermo</td>\n",
       "      <td>monotributista</td>\n",
       "      <td>matrimonio_civil</td>\n",
       "      <td>hombre</td>\n",
       "      <td>cristianismo</td>\n",
       "      <td>casado</td>\n",
       "      <td>directivo_gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palermo</td>\n",
       "      <td>relacion_de_dependencia</td>\n",
       "      <td>divorciado</td>\n",
       "      <td>hombre</td>\n",
       "      <td>cristianismo</td>\n",
       "      <td>sin_familia</td>\n",
       "      <td>limpiador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>palermo</td>\n",
       "      <td>relacion_de_dependencia</td>\n",
       "      <td>matrimonio_civil</td>\n",
       "      <td>hombre</td>\n",
       "      <td>judaismo</td>\n",
       "      <td>casado</td>\n",
       "      <td>limpiador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balvanera</td>\n",
       "      <td>relacion_de_dependencia</td>\n",
       "      <td>matrimonio_civil</td>\n",
       "      <td>mujer</td>\n",
       "      <td>judaismo</td>\n",
       "      <td>casada</td>\n",
       "      <td>profesional_especializado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      barrio     categoria_de_trabajo    estado_marital  genero      religion  \\\n",
       "0    palermo      empleado_provincial    sin_matrimonio  hombre  cristianismo   \n",
       "1    palermo           monotributista  matrimonio_civil  hombre  cristianismo   \n",
       "2    palermo  relacion_de_dependencia        divorciado  hombre  cristianismo   \n",
       "3    palermo  relacion_de_dependencia  matrimonio_civil  hombre      judaismo   \n",
       "4  balvanera  relacion_de_dependencia  matrimonio_civil   mujer      judaismo   \n",
       "\n",
       "  rol_familiar_registrado                    trabajo  \n",
       "0             sin_familia            entretenimiento  \n",
       "1                  casado          directivo_gerente  \n",
       "2             sin_familia                  limpiador  \n",
       "3                  casado                  limpiador  \n",
       "4                  casada  profesional_especializado  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_category = X.select_dtypes(include=['category'])\n",
    "X_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1537e-4dcf-496f-8616-fd1274721e19",
   "metadata": {},
   "source": [
    "Ahora discretizaremos las columnas numéricas y luego aplicaremos ODE a las columnas categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ae0abf-e422-41eb-a04d-b1ae1b170403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categ = discretize_columns(X)\n",
    "X_categ = apply_ODE(X_categ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8ff9f-0b23-4be4-abf2-67228151fbbf",
   "metadata": {},
   "source": [
    "Partimos nuestro set en *train* y *validation*, dejaremos un 20% de los datos para validación de nuestro entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65523fc8-5d69-408a-8080-ea52603e2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_categ, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aacc80-0728-4605-beeb-b802e31f85ea",
   "metadata": {},
   "source": [
    "Buscamos los mejores hiperparámetros para el modelo categoricalNB con GridSearchCV. La métrica que se utiliza para comparar los modelos obtenidos en cada iteracion es *roc_auc_score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7d41b-4bfb-41fa-b9a8-9bb6fd963a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'alpha': np.arange(0, 1, 0.01),\n",
    "}\n",
    "\n",
    "clf = CategoricalNB()\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    clf, parameters, scoring='roc_auc',n_jobs=-1, cv=5, return_train_score=True\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejor score ROC-AUC en Entrenamiento: {gscv.best_score_}\")\n",
    "print(f\"Mejores Parametros {gscv.best_params_}\")\n",
    "\n",
    "print(f\"\\nMejor score ROC-AUC en Validación: {gscv.score(X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c002ad-7912-450c-80eb-6fd69228ada8",
   "metadata": {},
   "source": [
    "Armamos el modelo de CategoricalNB con los hiperparámetros calculados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913ab3c-44a4-4f15-abce-72a4bea597fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_categoricalNB = gscv.best_estimator_\n",
    "model_categoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b3b7-0fee-48ee-add1-ee77cbee5bcb",
   "metadata": {},
   "source": [
    "Predecimos con el validation set. Similar a como lo hicimos en modelo anterior, aquí predecimos la probabilidades de pertenecer a dicha categoría lo cual nos servira mas adelante cuando querramos realizar el ensamble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb2116-3438-42a5-841e-c3f27e45d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalNB_predict = model_categoricalNB.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce569531-1635-408b-a830-eec6d0adf602",
   "metadata": {},
   "source": [
    "## Realizando el Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242e8a1-2177-4f2b-b450-23028228cecc",
   "metadata": {},
   "source": [
    "Para este ensamble optamos por utilizar el método de Voting, el cual recibe las prediciones de los anteriores modelos entrenados y mediante una medida de votación genera la predicción final. Los modelos que utilizamos para realizar el ensamble son los mostrados anteriormente: GaussianNB y CategoricalNB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14998e-2089-47f0-a24f-132d18389573",
   "metadata": {},
   "source": [
    "Primero generamos la siguiente función **ensamble_predict_proba** la cual recible las probabilidades de ambos modelos y devuleve la predicción final en forma de probabilidades. La lógica de la función es la siguiente: para cada clase, la probabilidad será el promedio de las probabilidades de ambos modelos para esa clase\n",
    "\n",
    "La predicción final resulta entonces del promedio de las probabilidades entre cada modelo para cada instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72c079-e46f-4d79-99d1-f3e65c674e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamble_predict_proba(gaussianNB_predict, categoricalNB_predict):\n",
    "    predictions_proba = []\n",
    "    for x in range(len(gaussianNB_predict)):\n",
    "        a = (gaussianNB_predict[x, 0] + categoricalNB_predict[x, 0])/2\n",
    "        b = (gaussianNB_predict[x, 1] + categoricalNB_predict[x, 1])/2\n",
    "        predictions_proba.append([a, b])\n",
    "    return predictions_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1822792-9946-4a7d-882a-c6b36044608a",
   "metadata": {},
   "source": [
    "La función **ensamble_predict** nos devolverá la clase con mayor probabilidad para cada instancia, luego de haber promediado las probabilidades de ambos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058853a8-a069-4eee-bd5e-f83fa65d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamble_predict(gaussianNB_predict, categoricalNB_predict):\n",
    "    predictions = []\n",
    "    predictions_proba = ensamble_predict_proba(gaussianNB_predict, categoricalNB_predict)\n",
    "    for prediction in np.array(predictions_proba)[:, 1]:\n",
    "        if(prediction > 0.5):\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0908e2e-d36c-4be7-b570-71c9dab0836e",
   "metadata": {},
   "source": [
    "Realizamos la predicción final en base a las predicciones de los anteriores modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af19b8-41ee-4eb1-851c-96f75ab637d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensambleNB_predict = ensamble_predict(gaussianNB_predict, categoricalNB_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e41c7d-15b4-41c1-92d6-7767023e6d70",
   "metadata": {},
   "source": [
    "**Metricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f9789-3dfc-4172-ab36-cca4497e3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_validation, ensambleNB_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811aa77-c3ba-42de-8964-ddd6d1ebb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrixDisplay(confusion_matrix(y_validation,ensambleNB_predict))\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f5c0e-9bf9-4fc1-8ad9-cad864c3ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_validation, np.array(ensamble_predict_proba(gaussianNB_predict, categoricalNB_predict))[:, 1])\n",
    "print(f\"\\nScore ROC-AUC en Validación: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be553bce-1d2e-4850-a480-263afba13cbe",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db9a04-a3e0-4d59-aaec-dc83a586b236",
   "metadata": {},
   "source": [
    "Vimos que usando únicamente el modelo gaussiano o el modelo categorical no tenemos una muy buena performance en la metrica *roc_auc*. Ahora si juntamos las predicciones de ambos mediante en un ensamble tenemos una mejora de dicha métrica aunque no llega a ser uno de los mejores modelos que tenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf02d5-903b-4516-9fde-59244527fb21",
   "metadata": {},
   "source": [
    "# Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb9507-5358-490e-94c7-34bd34d66050",
   "metadata": {},
   "source": [
    "Por último, con el ensamble obtenido realizaremos una predicción para datos que nunca vio en el entrenamiento ni en validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939ebf8-b366-4fad-95f6-243393ae57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, X_holdout = aux.get_holdout_set()\n",
    "X_holdout = init_dataset(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b7c3f-c433-4078-a7d4-47655bfa91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_continuos = X_holdout.select_dtypes(include=['int64','int32'])\n",
    "\n",
    "X_holdout_continuos = scale(X_holdout_continuos)\n",
    "X_holdout_categorical = discretize_columns(X_holdout_categorical)\n",
    "X_holdout_categorical = apply_ODE(X_holdout_categorical)\n",
    "\n",
    "gaussian_predict = model_gaussianNB.predict_proba(X_holdout_continuos)\n",
    "categorical_predict = model_categoricalNB.predict_proba(X_holdout_categorical)\n",
    "ensambleNB_predict = ensamble_predict(gaussian_predict, categorical_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa11c02-1184-41e4-b30f-917e0b3b92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.create_prediction(ids, ensambleNB_predict, file_name='ensambleNB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
